# Теория машинного обучения
[ссылка на модуль](https://apps.skillfactory.ru/learning/course/course-v1:SkillFactory+DSPR-2.0+14JULY2021/block-v1:SkillFactory+DSPR-2.0+14JULY2021+type@sequential+block@90618c930f1340f39069897b6300e298/block-v1:SkillFactory+DSPR-2.0+14JULY2021+type@vertical+block@63600b1337ed493e8e89bda4cc8f6a30)

> <font color="#00b050">Machine Learning (машинное обучение)</font> — это направление, объединяющее технологии создания самообучающихся алгоритмов.

![](Pasted%20image%2020240116195520.png)


## Искусственный интеллект

> <font color="#00b050">Искусственный интеллект (Artificial Intelligence, ИИ)</font> — это способность компьютерной системы имитировать когнитивные функции человека, такие как обучение и решение задач. ИИ позволяет компьютеру моделировать рассуждения людей для получения новых сведений и принятия решений (например, выдавать кредит заёмщику или нет).

Существует два типа искусственного интеллекта:

### Слабый ИИ (Weak AI)

> Слабый ИИ способен решать только одну задачу. Зачастую он справляется с ней даже лучше, чем человек. В качестве примера слабого ИИ можно назвать [Deep Blue](https://www.ibm.com/ibm/history/ibm100/us/en/icons/deepblue/). Это компьютерная программа, которая обыграла Гарри Каспарова в шахматы ещё в 1996 году. Но _Deep Blue_ не умеет делать ничего другого и никогда этому не научится.
> 
> Слабый ИИ используют в медицине, логистике, банковском деле, бизнесе.


### Сильный ИИ (Strong AI)

> Это интеллект, который решает множество задач и умеет обучаться для решения других. Сильный ИИ осознаёт себя и своё существование.

Сильный искусственный интеллект пока остаётся мечтой.

### В области искусственного интеллекта есть несколько подразделов:

- робототехника (_Robotics_),
- компьютерное зрение (_Computer Vision_),
- обработка естественного языка (_Natural Language Processing_),
- машинное обучение (_Machine Learning_).



## Машинное обучение

> Машинное обучение (Machine Learning) — это один из разделов науки об искусственном интеллекте. Машинное обучение заключается в построении моделей с помощью поиска закономерностей в данных и использовании их для того, чтобы спрогнозировать характеристики новых данных.

Машинное обучение как науку можно отнести к разделу прикладной математики. Оно находится на стыке статистики, математического анализа, линейной алгебры, численных методов оптимизации и дискретной математики.

### Всё машинное обучение держится на трёх очень важных столпах:

![](Pasted%20image%2020240116200204.png)

**Набор данных (dataset)** — это множество примеров (выборка), на котором происходит обучение модели. Это могут быть табличные данные, с которыми мы уже работали, текст, аудио, изображения (видео) и т. д.

**Признаки (features)** — это свойства, характеристики, которыми описываются наши объекты. Для недвижимости это могут быть площадь, этаж, район; для автомобиля — пробег, мощность двигателя, цвет и т. д.

Признак, который мы хотим предсказать, называется **целевым признаком (target feature)**. Иногда признаки, на основе которых мы хотим предсказать целевой, могут называться **факторами (factors)**.

**Модель машинного обучения (ML-model)** — это некоторый математически формализованный метод (алгоритм) описания зависимости в данных. Как правило, модель имеет настраиваемые (регулируемые) параметры.

Управляя своими параметрами, модель подстраивается под зависимости в данных, чтобы описать эту зависимость и свести ошибку в предсказаниях к минимуму. Такой процесс называется **обучением модели (model learning)**.

### Самый распространённый процесс обучения

Самый распространённый процесс обучения (обучение с минимизацией ошибки) модели можно описать упрощённой схемой:
![](Pasted%20image%2020240116200612.png)

`Предположим, мы обучаем модель для предсказания цены недвижимости. У нас есть некоторые факторы, например площадь дома, количество комнат в нём, коэффициент преступности в районе и т. д. Также есть _целевая переменная_ — собственно, цена недвижимости.`

`В модель поступают примеры описания домов — _факторы_. Модель на основе примеров выдаёт какое-то предсказание. В самом начале обучения модели результаты будут весьма странными и непредсказуемыми, поскольку, как правило, её параметры проинициализированы случайными значениями. Но если мы правильно поправим параметры, то сможем получить ответ, близкий к реальному. Но параметры могут изменяться как угодно — как выбрать правильные?`

> За управление параметрами отвечает некоторая функция ошибки, или, как её ещё называют, функция потерь (loss function). Это некоторая математическая функция, которая показывает различие между фактическими ответами и предсказаниями модели.

Самый простой пример функции ошибки — <font color="#00b050">MSE (Mean Squared Error)</font>, средний квадрат разницы между ответами. Формально она записывается следующим образом:

$$MSE = \frac{\sum_{i=1}^n(y_i-y'_i)^2}{n}$$

где $y$ — истинные ответы,  $y'$ — предсказания, $n$ — количество примеров.

`Теперь на основе значения _MSE_ меняем параметры таким образом, чтобы уменьшить эту ошибку`

> Рассмотренная схема называется обучением на основе минимизации ошибок, или, говоря более научным языком, минимизацией эмпирического риска (риска ошибки).
> 
> Стоит отметить, что такая схема обучения далеко не единственная и подходит не для всех моделей. Однако она является наиболее популярной.
> 
> Помимо обучения на основе ошибок, существуют следующие схемы:
> 
> - на основе прироста информации (используются в деревьях решений);
> - на основе «сходства» объектов (используется в методе ближайших соседей);
> - на основе вероятностных законов (например, метод максимального правдоподобия).
> 
> Более того, мы увидим, что бывают задачи, где нет правильных ответов, то есть мы не можем подсчитать функцию ошибки. Этот класс задач называется обучением без учителя.


==Метрика==

Для оценки качества модели вводится ещё одно понятие — <font color="#00b050">метрика</font>.

Метрика ≠ функция потерь.

> Метрика (metric) — это численное выражение качества модели (или её ошибки). Иногда метрика может совпадать с функцией потерь, но чаще всего они различны. Метрика, как правило, должна быть интерпретируемой и понятной — в этом её главное отличие от функции потерь.




## Глубокое обучение

> <font color="#00b050">Глубокое обучение (Deep Learning)</font> — подраздел машинного обучения. Глубокое обучение основано на изучении и применении в качестве инструмента для решения задач искусственных нейронных сетей. Данные алгоритмы основаны на имитации работы человеческого мозга.

## Итоги

- Искусственный интеллект — это общее название науки, которая занимается построением моделей, имитирующих деятельность человека. _Как, например, общий раздел — химия._
- Машинное обучение — это раздел искусственного интеллекта (важный, но не единственный), который сосредоточен на применении моделей машинного обучения для решения конкретных задач. __Как, например,_ подраздел химии — органическая химия._
- Глубокое обучение — это раздел машинного обучения, который сосредоточен на разработке и обучении нейронных сетей в качестве модели для решения сложных прикладных задач. __Как, например,_ подраздел органической химии — органическая химия углеводородов._



# Виды машинного обучения

## Вступление

![](Pasted%20image%2020240117151240.png)

В зависимости от наличия разметки в данных и особенностей обучения выделяют следующие виды машинного обучения:
- <font color="#00b050">обучение с учителем (supervised learning)</font>,
- <font color="#00b050">обучение без учителя (unsupervised learning).</font>

В отдельную категорию, не похожую на предыдущие, выделяют ещё один вид машинного обучения — <font color="#00b050">обучение с подкреплением (reinforcement learning)</font>.


## Обучение с учителем

![](Pasted%20image%2020240117152411.png)

> Данный вид обучения основан на том, что у машины есть некий учитель, который сообщает ей, как поступать правильно, рассказывает, что на этой картинке изображена кошка, а на этой — собака. То есть мы заранее разделили все данные на кошек и собак, а машина учится на конкретных примерах и правильных ответах к ним.
> Данные, в которых содержится информация о целевом признаке, называются размеченными.

`Процесс обучения с учителем можно сравнить с тем, как современный школьник готовится к сдаче ЕГЭ на высокий балл. Он решает огромное количество тренировочных вариантов, сверяясь с ответами в конце сборника и обучаясь на своих ошибках.`

Вид обучения с учителем включается в себя два основных типа задач: <font color="#00b050">регрессия</font> — предсказание числа и <font color="#00b050">классификация</font> — предсказание категории объекта.



### Регрессия

![](Pasted%20image%2020240117153349.png)

![](Pasted%20image%2020240117154612.png)

> Задача регрессии (regression) — это задача, в которой мы пытаемся предсказать вещественное число на основе признаков в наборе данных. То есть задача сводится к предсказанию целевого признака, который является числовым.

`Для регрессии всегда нужен учитель — размеченные данные с признаками и целевым признаком, который машина будет пытаться предсказать.`

==Цель обучения — построить модель, которая отражала бы зависимость между признаками и целевой числовой переменной.==

Классическими методами регрессии являются линейная (Linear) и полиномиальная (Polynomial) регрессия. Но они являются далеко не единственными.

> Полиномиальная регрессия использует в качестве модели полином (многочлен), который отражает нелинейную зависимость.

![](asset-v1%20SkillFactory+DST-3.0+28FEB2021+type@asset+block@dst3-ml1-3_6.png)



### Прогнозирование
> Прогнозирование (forecasting) — это задача регрессии, в которой мы пытаемся предсказать будущее поведение временного ряда, то есть целевая переменная является числовой и зависит от времени. <font color="#00b050">Причём каждому моменту времени соответствует одно конкретное значение</font>. Можно сказать, что прогнозирование — это частный случай регрессии.

Модели, которые разработаны специально для прогнозирования временных рядов:
- ARIMA,
- SARIMA (модификация _ARIMA_),
- ARCH (модель для финансовых временных рядов).



### Классификация

![](Pasted%20image%2020240117154538.png)

![](Pasted%20image%2020240117154630.png)

> Задача классификации (classification) — задача, в которой мы пытаемся предсказать класс объекта на основе признаков в наборе данных. То есть задача сводится к предсказанию целевого признака, который является категориальным.

`Для классификации всегда нужен учитель — размеченные данные с признаками и категориями, которые машина будет учиться определять по этим признакам.`

`Классифицировать можно всё что угодно: пользователей по интересам, статьи по языкам и тематикам, музыку по жанрам`

`Чаще всего мы сталкиваемся с бинарной классификацией.`

> Когда классов, которые мы хотим предсказать, более двух, классификация называется мультиклассовой (многоклассовой). Например, предсказание модели самолёта по радиолокационным снимкам, классификация животных на фотографиях, определение языка, на котором говорит пользователь, разделение писем на группы.

> Любую мультиклассовую задачу классификации можно свести к бинарной классификации методом «один против всех».
> Суть метода: какую-то из категорий мы обозначаем за 1, а оставшиеся за — 0 и решаем задачу бинарной классификации. Затем повторяем процедуру для остальных категорий.

==Цель обучения — построить модель, которая на основе признаков разделяет объекты на классы наилучшим образом. С математической точки зрения это означает построение _разделяющей поверхности_ для классов в пространстве признаков.==


```
На рисунке представлен пример разделяющей поверхности для классификации пингвинов на два класса: синими точками обозначены антарктические пингвины, красными — папуанские пингвины. Наблюдения рассматриваются в плоскости двух признаков: длина клюва пингвина и длина его крыльев.
```
![](asset-v1%20SkillFactory+DST-3.0+28FEB2021+type@asset+block@dst3-ml1-3_10.png)


Для решения задачи классификации может использоваться множество моделей:
- <font color="#00b050">логистическая регрессия (Logistic Regression)</font>,
- <font color="#00b050">метод опорных векторов (SVM)</font>,
- <font color="#00b050">деревья решений (Decision Tree)</font>,
- <font color="#00b050">наивный байесовский классификатор (Naive Bayes)</font>,
- <font color="#00b050">метод ближайших соседей (kNN)</font>.



## Обучение без учителя

![](Pasted%20image%2020240117155745.png)

> Обучение без учителя подразумевает, что у вас нет правильных ответов. То есть признак, который вы хотите предсказать, вам недоступен. Подход основан на том, что алгоритм самостоятельно выявляет зависимости в данных только на основе схожести объектов в данных между собой.

Данный вид машинного обучения разбивается на несколько самостоятельных типов задач:
- кластеризация,
- понижение размерности,
- ассоциация.


### Кластеризация
![](dst3-ml1-4_3.png)
> Задача кластеризации (clustering) — это задача, в которой мы разделяем данные на группы на основе признаков в данных.

На первый взгляд может показаться, что эта задача идентична классификации, но в задаче кластеризации у нас нет правильных ответов. То есть у нас нет учителя: мы пытаемся разделить данные на категории, опираясь только на «близость» объектов. Причём результаты каждого из алгоритмов кластеризации могут быть разными, потому что «близость» — понятие относительное и её можно измерять различными способами.

==Цель обучения — построить модель, которая наилучшим образом объединит «похожие» объекты в группы.==

Количество кластеров в зависимости от выбранного алгоритма можно задать заранее или доверить их количество алгоритму.

Типичные методы кластеризации при известном заранее количестве кластеров:
- <font color="#00b050">метод k-средних (k-means)</font>,
- <font color="#00b050">EM-алгоритм</font>,
- <font color="#00b050">агломеративная кластеризация</font>.

> Алгоритм <font color="#00b050">DBSCAN</font> сам находит скопления точек и строит вокруг кластеры. Очень рекомендуем посмотреть, как происходит процесс кластеризации алгоритмом _DBSCAN_ [в динамике](https://www.youtube.com/watch?v=krpNHsM267A&t=13s). Это захватывающее зрелище.

![](Pasted%20image%2020240119153529.png)



### Понижение размерности (обобщение)

![](dst3-ml1-4_6.png)

> Понижение размерности (dimensionality reduction) — задача, в которой мы пытаемся уменьшить количество признаков, характеризующих объект. Обычно мы уменьшаем количество признаков до 2-3 для того, чтобы получить возможность визуализировать данные.

Представим, что у нас есть целевой признак цены и он зависит от 20 параметров. Мы хотим построить диаграмму рассеяния, которая показывает зависимость от всех признаков сразу. Если мы возьмём трёхмерную визуализацию, то целевой признак мы отложим по оси _z_, один из числовых признаков — по оси _x_, ещё один — по оси _y_. Оси закончились! Мы не можем отобразить четырёхмерную визуализацию.
В модуле по визуализации мы говорили, что при большом желании можно также добавить признаки в виде цвета, формы и размеров точек на графике. Но, как бы мы ни старались, все 20 признаков на диаграмме нам не уместить. Кроме того, такая диаграмма становится всё менее читабельной с добавлением каждого нового признака.

Выход из этой ситуации — использовать методы понижения размерности.
- Практическая польза этих методов состоит в том, что мы можем объединить несколько признаков в один и получить абстракцию.
    Например, собаки с треугольными ушами, длинными носами и большими хвостами объединяются в полезную абстракцию «овчарки». Да, мы теряем информацию о конкретных овчарках, но новая абстракция точно полезнее этих лишних деталей.
- Ещё одно проявление пользы таких алгоритмов — увеличение скорости обучения. Мы уже говорили о проклятии размерности: «чем больше признаков в данных, тем сложнее модели обучиться на них». Методы понижения размерности позволяют свести эту проблему к минимуму. Однако точность моделей может сильно упасть, поэтому необходимо уметь находить баланс.
- Ещё один приятный бонус — мы автоматически избавляемся от мультиколлинеарности признаков. Методы понижения размерности устроены так, что в первую очередь объединяют между собой наиболее коррелированные признаки.


==Цель обучения — построить модель, которая переводит пространство признаков из размерности $n$ в размерность $m\ (m<n)$, при этом сохранив наибольший объём информации. Математически это записывается как $a: X^n \rightarrow X^m$.==

На рисунке ниже представлен пример понижения размерности данных с двух признаков до одного. Используемый алгоритм — метод главных компонент (Principal Component Analysis, PCA). С помощью него находится обобщающая ось (компонента), которая содержит наибольшее количество информации о признаках. Наблюдения проецируются на новую ось, в результате чего получается новый признак, который является обобщением двух предыдущих. Обучение состоит в поиске оптимальной оси обобщения, которая содержит наибольший объём информации.

![](Pasted%20image%2020240119154844.png)

Основные алгоритмы понижения размерности:
- <font color="#00b050">метод главных компонент (PCA)</font>,
- <font color="#00b050">сингулярное разложение (SVD)</font>,
- <font color="#00b050">латентное размещение Дирихле (LDA)</font>,
- <font color="#00b050">латентный семантический анализ (LSA)</font>,
- <font color="#00b050">t-SNE</font>.



### Ассоциация

![](dst3-ml1-4_10.png)

> Ассоциация (association) — это задача, в которой мы пытаемся найти правила и законы, по которым существует последовательность действий. Давайте сразу перейдём к примерам.

Мы можем создавать различные шаблоны, такие как определённые группы предметов, которые постоянно покупаются вместе, предметы, похожие на предметы, которые вы просматриваете, и т. д. Это, в свою очередь, помогает в правильном размещении предметов на веб-сайте или внутри физического заведения.

Основные ассоциативные модели:
- <font color="#00b050">Apriori</font>,
- <font color="#00b050">Eclat</font>,
- <font color="#00b050">FP Growth</font>.



## Обучение с подкреплением

![](Pasted%20image%2020240119155347.png)

![](dst3-ml1-5_2.png)

> Это не задачи, связанные с анализом данных и предсказанием, а задачи взаимодействия со средой и «выживания» в ней.

`Средой может быть видеоигра: в такой искусственной среде «выживают», например, роботы, играющие в _Mario_, или интеллектуальные боты во множестве других игр.`
`Средой может быть и реальный мир, точнее — его часть: в такой среде существуют, например, автопилот _Tesla_, роботы-пылесосы или беспилотные летательные аппараты.`

> Объект, который взаимодействует со средой (например, играет в игру), называется агентом.

Агент может получать от среды полные или частичные наблюдения о её состоянии. Он может выполнять действия согласно своим наблюдениям. По мере совершения действий агент может получить в ответ награду от среды.

![](Pasted%20image%2020240119155548.png)


==Поэтому цель обучения — не рассчитать все ходы, а построить оптимальную стратегию для взаимодействия со средой и максимизировать финальную награду.==

Выживание в среде — это и есть идея обучения с подкреплением. Давайте бросим бедного агента на растерзание судьбе и дадим ему неограниченное число жизней. Будем штрафовать его за ошибки и награждать за правильные поступки.

В математике уже давно известны методы, которые позволяют находить оптимальную стратегию. В основе обучения с подкреплением лежат теория игр, теория динамической оптимизации и ещё множество математических дисциплин.

Например, классический метод обучения с подкреплением — Q-learning — основан на [уравнении Беллмана](https://habr.com/ru/post/443240/).

> В _Q-learning_ рассматриваются все состояния, в которых может находиться агент, и все возможные переходы из одного состояния в другое, которые определяются действиями.
> Уравнение Беллмана помогает определить следующее оптимальное действие, такое, что значение _Q_-функции для определённой пары _состояние-действие_ будет максимальной.

==Цель Q-learning — приближённо найти (аппроксимировать) _Q_-функцию, которая ответит на вопрос, как нужно правильно играть, чтобы получить максимум награды.==

Однако чем больше состояний, тем сложнее отыскать _Q_-функцию.

Для сложных задач — сложные решения. В таких случаях для поиска сложных _Q_-функций привлекаются нейронные сети, а такое обучение носит название <font color="#00b050">Deep Q-Network (DQN).</font>

На идеях _Q-learning_ основаны и другие алгоритмы, например алгоритм _SARSA_. Подробнее об алгоритмах можно почитать [здесь](https://habr.com/ru/post/561746/).

> Отдельный пласт в сфере обучения с подкреплением — генетические алгоритмы. Их идея отличается от идей _Q-learning_ и состоит в следующем: мы бросаем множество агентов в среду и заставляем их идти к цели. Затем мы выбираем лучших из них — тех, кто прошёл дальше всех, скрещиваем, добавляем мутации и бросаем в среду ещё раз. Такие манипуляции мы проделываем огромное количество раз. В итоге по законам эволюции должно получиться разумное существо.

==Как выяснилось на практике, генетические алгоритмы значительно уступают в скорости обучения методам _Q-learning_ и их производным, поэтому они используются всё реже.==



# Процесс разработки

юбая задача машинного обучения (классификация, регрессия, кластеризация и так далее) — это по сути обычная оптимизационная задача.

> Эта последовательность действий по работе над проектом называется методологией разработки (моделью процесса разработки).



## Методология waterfall

![](Pasted%20image%2020240121142551.png)

Особенности методологии:
- Разработка происходит строго последовательно, этап за этапом. Переход на предыдущий этап не предусмотрен или требует формального процесса, например подачи заявки на изменения в организационный комитет и её одобрения.
- Планирование ведётся на всю длительность проекта в самом его начале.
- Все действия максимально регламентированы и спланированы до мелочей. Установлены чёткие сроки окончания каждого из этапов.
- По окончании каждого из этапов происходит формальная сдача результатов именно этого этапа в виде большого числа документов. Например, после этапа анализа требований заказчика рождается техническое задание (ТЗ), а после этапа тестирования — документ, который называется «Программа и методика испытаний». В РФ для содержания большинства документов предусмотрены ГОСТы.
- Результаты каждого из этапов тщательно проверяются на наличие ошибок. Только после исправления всех ошибок на текущем этапе команда может перейти на следующий этап.
- Готовый продукт передаётся заказчику только один раз в конце проекта (второй попытки не предусмотрено). У команды есть только один шанс на сдачу проекта, поэтому внимание к деталям и документации максимально пристальное.



### Где стоит использовать Waterfall?

> _Waterfall_ используется в проектах, где отсутствует неопределённость в требованиях заказчика: проект достаточно понятный и его можно спланировать в самом начале. То есть результат можно чётко представить заранее.

> Методология особенно необходима в проектах, которые сопровождаются высокими затратами в случае провала. Это связано с тщательным отслеживанием каждого из этапов и уменьшением риска допустить ошибку. Уменьшение риска особенно критично в проектах оборонной и космической промышленности.


### Почему waterfall нам не подходит?

> → В условиях такой неопределённости планирование проекта в самом его начале — пустая трата времени. Представьте, что у вас на руках некорректные данные и вы строите на их основе только гипотезы и догадки. Когда у вас появится новая информация о предмете проекта, вам может понадобиться полностью перезагрузить эту гигантскую машину, на которой работает планирование в _Waterfall_. А это означает новое планирование, новый запуск этапов, а как следствие, срыв сроков!

Отсюда возникла потребность придумать более гибкую методологию. Так, в феврале 2001 года в штате Юта (США) был выпущен [«Манифест гибкой разработки программного обеспечения»](https://ru.wikipedia.org/wiki/Agile_Manifesto), описывающий новую методологию разработки проектов, которая получила название Agile.



## Методология Agile

> <font color="#00b050">Гибкая методология (Agile)</font> — это модель процесса разработки ПО с гибким возвратом к любому этапу: если тест спроектированной модели не дал нужного результата, то разработчик может начать с самого начала.

Этапы каждой из итераций такие же, как в _Waterfall_, с добавлением этапа демонстрации промежуточных результатов заказчику.

> Проект реализуется не как последовательность длительных этапов (как это было в _Waterfall_), а как ряд коротких временных отрезков — спринтов, на каждом из которых прогоняются все этапы.

![](Pasted%20image%2020240121143459.png)


Особенности методологии:
- Разработка происходит по итерациям. В конце каждой итерации промежуточный результат демонстрируется заказчику. Заказчик даёт обратную связь (устраивает ли его эта часть функционала). Итерации заканчиваются, когда готов финальный продукт и он устраивает заказчика. 
- Проект планируется только на один спринт. Длительность спринтов — от одной до четырёх недель. То есть вам необходимо продумать задачи только на короткий промежуток времени, что сильно повышает точность планирования.
- В случае если у вас что-то не получилось (например, модель показывает низкое качество), вы просто переходите на новую итерацию и теряете только время, потраченное на один спринт, а не на весь проект в целом.
- _Agile_ не предусматривает множества формальных документов, в отличие от _Waterfall_.
- Команда полностью вовлечена в процесс, так как отсутствует формальная иерархия. Методология считается демократичной. Главный принцип — люди важнее процессов и инструментов.
- Заказчик видит продукт на протяжении всей разработки и может вносить коррективы (не выходящие за рамки изначального задания). Проект сдаётся, когда выполнены все требования и они устраивают заказчика.



### Где стоит использовать Agile?

> _Agile_ используется в тех случаях, когда в проекте есть неопределённость. Ни заказчик, ни пользователи, ни разработчики пока что полностью не представляют, что должно получиться в итоге.

`Это разработка новых продуктов, которые требуют постоянной обратной связи. Вы и заказчик делаете эксперименты-расследования, маленькими шагами узнавая что-то новое о своём проекте.`



### Недостатки Agile
1. _Agile_ — это общая модель процесса разработки продукта, причём не только из сферы _IT_. Методология не учитывает особенности работы _Data Science_ команды. Например, видите ли вы в процессе _Agile_-разработки такие этапы, как подбор параметров модели или расчёт метрик её качества? Куда их включить — в этап разработки или, может быть, в тестирование? _Agile_ об этом не говорит.
2. _DS_-команда может сдерживать _Agile_-разработку команды разработчиков ПО, потому что дата-сайентисты долго перебирают возможные модели. Постоянная настройка модели иногда может сдерживать ощутимый прогресс.
3. Документирование не регламентировано. В _DS_-проектах документация и история всех используемых моделей очень важна, позволяет экономить время и облегчает возможность вернуться к изначальному решению.


Предлагаем вам прочитать замечательную [статью](https://vc.ru/flood/20942-agile-victims) генерального директора _Accera_ о том, как _Agile_ может погубить компанию.



## Методология CRISP-DM

> <font color="#00b050">CRISP-DM (Cross-Industry Standard Process for Data Mining)</font> — наиболее распространённая и проверенная методология по работе с проектами, завязанными на данных. Модель жизненного цикла исследования данных в методологии состоит из шести фаз, а стрелки обозначают наиболее важные и частые зависимости между фазами.

![](Pasted%20image%2020240121144110.png)

Особенности методологии:
- Методология _CRISP-DM_ разработана специалистами по работе с данными и учитывает особенности _DS_-проектов.
- Иногда говорят, что _CRISP-DM_ является обобщением методологии _Agile_ на _DS_. В частности, методология является итеративной (проект состоит из спринтов).
- Последовательность этапов строго не определена, некоторые этапы можно менять местами. Возможна параллельность этапов (например, подготовка данных и их исследования могут вестись одновременно). Предусмотрены возвраты на предыдущие этапы.
- Фиксирование ключевых моментов проекта: графиков, найденных закономерностей, результатов проверки гипотез, используемых моделей и полученных метрик на каждой итерации цикла разработки.


[Демонстрация CRISP-DM](Демонстрация%20CRISP-DM.md)



## Проблемы при разработке

1. Непонятно, сколько времени закладывать на разработку модели. На первый взгляд простая задача может отнять очень много времени и сорвать сроки.
    Предобработка данных, выбор и обучение модели, анализ результатов занимают много времени, но точно определить конкретные промежутки невозможно. Какие-то процессы могут потребовать возврата и доработки, возможен откат на старт.

2. Невозможно с первого раза сделать идеальную рабочую модель.
	Идеальная модель — это модель, которая решает задачу с нулевой ошибкой или 100 %-ой точностью. Очевидно, что такой модели не существует в природе. Мы можем лишь пытаться повысить качество моделирования и приблизить его к максимальному, что может потребовать множества итераций разработки.

3. Модель начинает приносить бизнес-пользу только после этапа внедрения.
	Пока ваша модель не введена в эксплуатацию, она никому не нужна. Если у вас стартап, завязанный на машинном обучении, то деньги он начнёт приносить только после разработки самой модели.

4. Не уделили внимание подготовке данных.
	Если процесс предобработки занимает подозрительно мало времени, то, скорее всего:
	- не учтены бизнес-требования;
	- не проведена работа по исследованию данных;
	- недостаточно опытные разработчики/аналитики;
	- недостаточно данных.




## Советы и лайфхаки

- Распределяйте роли. В идеале в команде разработчиков необходимо иметь разных специалистов — _Data Engineer_, _Data Scientist_ и _Data Analyst_. Каждый из них лучше разбирается в конкретных процессах.
- Выберите правильную метрику (сколько пользы бизнесу принесёт ML). Разберитесь, какая метрика лучше подходит для какой задачи, как её можно улучшать.
- Правильно пользуйтесь инструментами. Не усложняйте, ищите готовые решения и библиотеки и адаптируйте под свои цели.
- Будьте терпеливы. В _Data Science_-разработке обычно невозможно заранее сказать, какие гипотезы подтвердятся. Не торопитесь — неверно подобранная гипотеза может дорого обойтись позже. Уделите время тщательному подбору.
- Чётко формулируйте требования разметки, если нанимаете фрилансеров. Распишите правила принятия решения, покажите на примерах. Лучше всего будет показать на видео, как вы размечаете данные.



